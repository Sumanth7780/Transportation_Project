{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    PCARD_NO      RIDE_DTIME  TRANS_ID  TRANSP_METHOD_CD  \\\n",
      "0       E00E0000500000GB5609  20130113091321         1               105   \n",
      "1       E00E0000500000GB5609  20130113212157         2               120   \n",
      "2       E00E0000500000GB5609  20130113214519         2               105   \n",
      "3       E00E000E000005G95FFC  20130113054935        13               115   \n",
      "4       E00E000E000005G95FFC  20130113052856        13               120   \n",
      "...                      ...             ...       ...               ...   \n",
      "175907      E909F909G5E6FB06  20130119191705        12               200   \n",
      "175908      E909F909G5E6FB06  20130119200511        12               115   \n",
      "175909      E909F909FGBB0006  20130119222710        19               200   \n",
      "175910      E909F909FGBB0006  20130119114944        18               200   \n",
      "175911      GC09F90F0F905305  20130119180907        27               115   \n",
      "\n",
      "        TRAF_FREQ  BUS_ROUTE_ID  RIDE_TRANSP_BIZR_ID      VEHC_ID  \\\n",
      "0               0    11110637.0            111504071  111707302.0   \n",
      "1               0    41110072.0            111008051  111747102.0   \n",
      "2               1    11110637.0            111504071  111757205.0   \n",
      "3               1    11110041.0            111007500  111705913.0   \n",
      "4               0    11110267.0            111007500  111747043.0   \n",
      "...           ...           ...                  ...          ...   \n",
      "175907          0           NaN            211100000          NaN   \n",
      "175908          1    11110049.0            111004301  111751483.0   \n",
      "175909          0           NaN            211200000          NaN   \n",
      "175910          0           NaN            211100000          NaN   \n",
      "175911          0    11110998.0            111002000  111744049.0   \n",
      "\n",
      "        PCARD_USER_CLASS_CD  RIDE_STA_ID  ...  ALIGHT_AMT  RUN_DEPART_DTIME  \\\n",
      "0                         1      9013083  ...         0.0      2.013011e+13   \n",
      "1                         1         8809  ...         0.0      2.013011e+13   \n",
      "2                         1      9012213  ...         0.0      2.013011e+13   \n",
      "3                         1      8001908  ...         0.0      2.013011e+13   \n",
      "4                         1      8501164  ...         0.0      2.013011e+13   \n",
      "...                     ...          ...  ...         ...               ...   \n",
      "175907                    1         1906  ...       200.0               NaN   \n",
      "175908                    1        71190  ...       300.0      2.013012e+13   \n",
      "175909                    1         2640  ...       200.0               NaN   \n",
      "175910                    1         1813  ...       200.0               NaN   \n",
      "175911                    1        74596  ...         0.0      2.013012e+13   \n",
      "\n",
      "        FARE_USER_CLASS_CD1  FARE_USER_CLASS_CD2  FARE_USER_CLASS_CD3  \\\n",
      "0                         1                  NaN                  NaN   \n",
      "1                         1                  NaN                  NaN   \n",
      "2                         1                  NaN                  NaN   \n",
      "3                         1                  NaN                  NaN   \n",
      "4                         1                  NaN                  NaN   \n",
      "...                     ...                  ...                  ...   \n",
      "175907                    1                  NaN                  NaN   \n",
      "175908                    1                  NaN                  NaN   \n",
      "175909                    1                  NaN                  NaN   \n",
      "175910                    1                  NaN                  NaN   \n",
      "175911                    1                  NaN                  NaN   \n",
      "\n",
      "        PASGR_NUM1  PASGR_NUM2  PASGR_NUM3  USE_DIST  USE_TIME  \n",
      "0                1           0           0    1681.0     449.0  \n",
      "1                1           0           0    4647.0     847.0  \n",
      "2                1           0           0    1681.0     566.0  \n",
      "3                1           0           0    3944.0     728.0  \n",
      "4                1           0           0    4395.0     596.0  \n",
      "...            ...         ...         ...       ...       ...  \n",
      "175907           1           0           0   19500.0    2498.0  \n",
      "175908           1           0           0   11479.0    2008.0  \n",
      "175909           1           0           0   19400.0    3259.0  \n",
      "175910           1           0           0   19400.0    3274.0  \n",
      "175911           1           0           0    6680.0    1603.0  \n",
      "\n",
      "[175912 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"E:\\\\data\\\\201301\\\\unique_pcard\\\\01_13.csv\")\n",
    "\n",
    "df2 = pd.read_csv(\"E:\\\\data\\\\201301\\\\unique_pcard\\\\01_14.csv\")\n",
    "df3 = pd.read_csv(\"E:\\\\data\\\\201301\\\\unique_pcard\\\\01_15.csv\")\n",
    "df4 = pd.read_csv(\"E:\\\\data\\\\201301\\\\unique_pcard\\\\01_16.csv\")\n",
    "df5 = pd.read_csv(\"E:\\\\data\\\\201301\\\\unique_pcard\\\\01_17.csv\")\n",
    "df6 = pd.read_csv(\"E:\\\\data\\\\201301\\\\unique_pcard\\\\01_18.csv\")\n",
    "df7 = pd.read_csv(\"E:\\\\data\\\\201301\\\\unique_pcard\\\\01_19.csv\")\n",
    "df = pd.concat([df1,df2,df3,df4,df5,df6,df7], ignore_index=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific(df):\n",
    "    specific_pcard='FG09FF5363B0F05E'\n",
    "\n",
    "    # Filter the DataFrame for rows where 'PCARD_NO' matches the specific payment card number\n",
    "    filtered_rows = df[df['PCARD_NO'] == specific_pcard]\n",
    "\n",
    "    return filtered_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11_1=specific(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PCARD_NO      RIDE_DTIME  TRANS_ID  TRANSP_METHOD_CD  \\\n",
      "23238   FG09FF5363B0F05E  20130113054611        80               105   \n",
      "23239   FG09FF5363B0F05E  20130113060236        80               105   \n",
      "48575   FG09FF5363B0F05E  20130114062931        81               105   \n",
      "48576   FG09FF5363B0F05E  20130114061141        81               105   \n",
      "74116   FG09FF5363B0F05E  20130115054313        82               105   \n",
      "74117   FG09FF5363B0F05E  20130115060236        82               105   \n",
      "99668   FG09FF5363B0F05E  20130116062940        83               105   \n",
      "99669   FG09FF5363B0F05E  20130116060943        83               105   \n",
      "124816  FG09FF5363B0F05E  20130117060254        84               105   \n",
      "124817  FG09FF5363B0F05E  20130117054324        84               105   \n",
      "150434  FG09FF5363B0F05E  20130118060908        85               105   \n",
      "150435  FG09FF5363B0F05E  20130118062954        85               105   \n",
      "175482  FG09FF5363B0F05E  20130119054328        86               105   \n",
      "175483  FG09FF5363B0F05E  20130119060351        86               105   \n",
      "\n",
      "        TRAF_FREQ  BUS_ROUTE_ID  RIDE_TRANSP_BIZR_ID      VEHC_ID  \\\n",
      "23238           0    11110514.0            111501570  111753653.0   \n",
      "23239           1    11110586.0            111519470  111753369.0   \n",
      "48575           1    11110514.0            111501570  111753618.0   \n",
      "48576           0    11110586.0            111519470  111753471.0   \n",
      "74116           0    11110648.0            111501570  111753620.0   \n",
      "74117           1    11110586.0            111519470  111706631.0   \n",
      "99668           1    11110514.0            111501570  111753653.0   \n",
      "99669           0    11110587.0            111519470  111753470.0   \n",
      "124816          1    11110586.0            111519470  111753166.0   \n",
      "124817          0    11110648.0            111501570  111753620.0   \n",
      "150434          0    11110587.0            111519470  111753472.0   \n",
      "150435          1    11110514.0            111501570  111753653.0   \n",
      "175482          0    11110648.0            111501570  111753620.0   \n",
      "175483          1    11110586.0            111519470  111753168.0   \n",
      "\n",
      "        PCARD_USER_CLASS_CD  RIDE_STA_ID  ...  ALIGHT_AMT  RUN_DEPART_DTIME  \\\n",
      "23238                     1      9009151  ...         0.0      2.013011e+13   \n",
      "23239                     1      9011993  ...         0.0      2.013011e+13   \n",
      "48575                     1      9009056  ...         0.0      2.013011e+13   \n",
      "48576                     1      9009540  ...         0.0      2.013011e+13   \n",
      "74116                     1      9009151  ...         0.0      2.013012e+13   \n",
      "74117                     1      9011993  ...         0.0      2.013012e+13   \n",
      "99668                     1      9009056  ...         0.0      2.013012e+13   \n",
      "99669                     1      9009540  ...         0.0      2.013012e+13   \n",
      "124816                    1      9011993  ...         0.0      2.013012e+13   \n",
      "124817                    1      9009151  ...         0.0      2.013012e+13   \n",
      "150434                    1      9009540  ...         0.0      2.013012e+13   \n",
      "150435                    1      9009056  ...         0.0      2.013012e+13   \n",
      "175482                    1      9009151  ...         0.0      2.013012e+13   \n",
      "175483                    1      9011993  ...         0.0      2.013012e+13   \n",
      "\n",
      "        FARE_USER_CLASS_CD1  FARE_USER_CLASS_CD2  FARE_USER_CLASS_CD3  \\\n",
      "23238                     1                  NaN                  NaN   \n",
      "23239                     1                  NaN                  NaN   \n",
      "48575                     1                  NaN                  NaN   \n",
      "48576                     1                  NaN                  NaN   \n",
      "74116                     1                  NaN                  NaN   \n",
      "74117                     1                  NaN                  NaN   \n",
      "99668                     1                  NaN                  NaN   \n",
      "99669                     1                  NaN                  NaN   \n",
      "124816                    1                  NaN                  NaN   \n",
      "124817                    1                  NaN                  NaN   \n",
      "150434                    1                  NaN                  NaN   \n",
      "150435                    1                  NaN                  NaN   \n",
      "175482                    1                  NaN                  NaN   \n",
      "175483                    1                  NaN                  NaN   \n",
      "\n",
      "        PASGR_NUM1  PASGR_NUM2  PASGR_NUM3  USE_DIST  USE_TIME  \n",
      "23238            1           0           0    1058.0     255.0  \n",
      "23239            1           0           0    1527.0     366.0  \n",
      "48575            1           0           0    1047.0     227.0  \n",
      "48576            1           0           0    1702.0     317.0  \n",
      "74116            1           0           0    1058.0     208.0  \n",
      "74117            1           0           0    1527.0     407.0  \n",
      "99668            1           0           0    1047.0     209.0  \n",
      "99669            1           0           0    1703.0     435.0  \n",
      "124816           1           0           0    1527.0     370.0  \n",
      "124817           1           0           0    1058.0     215.0  \n",
      "150434           1           0           0    1703.0     467.0  \n",
      "150435           1           0           0    1047.0     244.0  \n",
      "175482           1           0           0    1058.0     280.0  \n",
      "175483           1           0           0    1527.0     440.0  \n",
      "\n",
      "[14 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_11_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_date_time(df):\n",
    "    df['ALIGHT_DTIME'] = df['ALIGHT_DTIME'].astype(str)\n",
    "    \n",
    "    if 'ALIGHT_DTIME' in df.columns:\n",
    "        df['ALIGHT_DATE'] = pd.to_datetime(df['ALIGHT_DTIME'].str[:8], format='%Y%m%d')\n",
    "        df['ALIGHT_TIME'] = pd.to_datetime(df['ALIGHT_DTIME'].str[8:14], format='%H%M%S', errors='coerce').dt.time\n",
    "    else:\n",
    "        # Handle case where 'ALIGHT_DTIME' may not exist\n",
    "        df['ALIGHT_DATE'] = pd.NaT\n",
    "        df['ALIGHT_TIME'] = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_time(df):    \n",
    "    df['RIDE_DTIME'] = df['RIDE_DTIME'].astype(str)\n",
    "\n",
    "    # Process 'RIDE_DTIME' to extract date and time\n",
    "    if 'RIDE_DTIME' in df.columns:\n",
    "        df['RIDE_DATE'] = pd.to_datetime(df['RIDE_DTIME'].str[:8], format='%Y%m%d')\n",
    "        df['RIDE_TIME'] = pd.to_datetime(df['RIDE_DTIME'].str[8:14], format='%H%M%S', errors='coerce').dt.time\n",
    "    else:\n",
    "        # Handle case where 'ALIGHT_DTIME' may not exist\n",
    "        df['RIDE_DATE'] = pd.NaT\n",
    "        df['RIDE_TIME'] = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_time(df)\n",
    "df=data_date_time(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PCARD_NO      RIDE_DTIME  TRANS_ID  TRANSP_METHOD_CD  TRAF_FREQ  \\\n",
      "0    000E0E0E96E3BFC3  20131215151434       175               200          0   \n",
      "1    000E0E0E96E3BFC3  20131215155940       176               200          0   \n",
      "2    000E0E0E96E3BFC3  20131215182458       177               200          0   \n",
      "3    000E0E0E96E3BFC3  20131215194613        21               105          0   \n",
      "4    000E0E0E96E3BFC3  20131216073731       178               200          0   \n",
      "..                ...             ...       ...               ...        ...   \n",
      "197  000E0E0E96E3BFC3  20131221134740       154               200          0   \n",
      "198  000E0E0E96E3BFC3  20131221111346       149               200          0   \n",
      "199  000E0E0E96E3BFC3  20131221154538       159               200          0   \n",
      "200  000E0E0E96E3BFC3  20131221160704       160               200          0   \n",
      "201  000E0E0E96E3BFC3  20131221192717       165               200          0   \n",
      "\n",
      "     BUS_ROUTE_ID  RIDE_TRANSP_BIZR_ID      VEHC_ID PCARD_USER_CLASS_CD  \\\n",
      "0             NaN            211000000          NaN                   6   \n",
      "1             NaN            211000000          NaN                   6   \n",
      "2             NaN            211200000          NaN                   6   \n",
      "3      11110084.0            111520030  111755108.0                   6   \n",
      "4             NaN            211000000          NaN                   6   \n",
      "..            ...                  ...          ...                 ...   \n",
      "197           NaN            211000000          NaN                  06   \n",
      "198           NaN            211000000          NaN                  06   \n",
      "199           NaN            211000000          NaN                  06   \n",
      "200           NaN            211000000          NaN                  06   \n",
      "201           NaN            211000000          NaN                  06   \n",
      "\n",
      "     RIDE_STA_ID  ... FARE_USER_CLASS_CD3  PASGR_NUM1  PASGR_NUM2  PASGR_NUM3  \\\n",
      "0            311  ...                 NaN           1           0           0   \n",
      "1            153  ...                 NaN           1           0           0   \n",
      "2           2535  ...                 NaN           1           0           0   \n",
      "3        9012125  ...                 NaN           1           0           0   \n",
      "4            311  ...                 NaN           1           0           0   \n",
      "..           ...  ...                 ...         ...         ...         ...   \n",
      "197          223  ...                 NaN           1           0           0   \n",
      "198          223  ...                 NaN           1           0           0   \n",
      "199          220  ...                 NaN           1           0           0   \n",
      "200          223  ...                 NaN           1           0           0   \n",
      "201          237  ...                 NaN           1           0           0   \n",
      "\n",
      "     USE_DIST  USE_TIME  RIDE_DATE  RIDE_TIME  ALIGHT_DATE  ALIGHT_TIME  \n",
      "0      9700.0    1518.0 2013-12-15   15:14:34   2013-12-15     15:39:52  \n",
      "1       900.0     197.0 2013-12-15   15:59:40   2013-12-15     16:02:57  \n",
      "2      9700.0    2435.0 2013-12-15   18:24:58   2013-12-15     19:05:33  \n",
      "3      1058.0     524.0 2013-12-15   19:46:13   2013-12-15     19:54:57  \n",
      "4     22400.0    2793.0 2013-12-16   07:37:31   2013-12-16     08:24:04  \n",
      "..        ...       ...        ...        ...          ...          ...  \n",
      "197     900.0     267.0 2013-12-21   13:47:40   2013-12-21     13:52:07  \n",
      "198     900.0     306.0 2013-12-21   11:13:46   2013-12-21     11:18:52  \n",
      "199    3200.0     756.0 2013-12-21   15:45:38   2013-12-21     15:58:14  \n",
      "200    4000.0    1055.0 2013-12-21   16:07:04   2013-12-21     16:24:39  \n",
      "201   10700.0    2323.0 2013-12-21   19:27:17   2013-12-21     20:06:00  \n",
      "\n",
      "[202 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_time(time):\n",
    "    if time >= pd.to_datetime('06:00:00').time() and time <= pd.to_datetime('10:00:00').time():\n",
    "        return 'Morning Peak (MP)'\n",
    "    elif time >= pd.to_datetime('16:00:00').time() and time <= pd.to_datetime('20:00:00').time():\n",
    "        return 'Afternoon Peak (AP)'\n",
    "    else:\n",
    "        return 'Non-Peak (NP)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PCARD_NO      RIDE_DTIME  TRANS_ID  TRANSP_METHOD_CD  TRAF_FREQ  \\\n",
      "0    000E0E0E96E3BFC3  20131215151434       175               200          0   \n",
      "1    000E0E0E96E3BFC3  20131215155940       176               200          0   \n",
      "2    000E0E0E96E3BFC3  20131215182458       177               200          0   \n",
      "3    000E0E0E96E3BFC3  20131215194613        21               105          0   \n",
      "4    000E0E0E96E3BFC3  20131216073731       178               200          0   \n",
      "..                ...             ...       ...               ...        ...   \n",
      "197  000E0E0E96E3BFC3  20131221134740       154               200          0   \n",
      "198  000E0E0E96E3BFC3  20131221111346       149               200          0   \n",
      "199  000E0E0E96E3BFC3  20131221154538       159               200          0   \n",
      "200  000E0E0E96E3BFC3  20131221160704       160               200          0   \n",
      "201  000E0E0E96E3BFC3  20131221192717       165               200          0   \n",
      "\n",
      "     BUS_ROUTE_ID  RIDE_TRANSP_BIZR_ID      VEHC_ID PCARD_USER_CLASS_CD  \\\n",
      "0             NaN            211000000          NaN                   6   \n",
      "1             NaN            211000000          NaN                   6   \n",
      "2             NaN            211200000          NaN                   6   \n",
      "3      11110084.0            111520030  111755108.0                   6   \n",
      "4             NaN            211000000          NaN                   6   \n",
      "..            ...                  ...          ...                 ...   \n",
      "197           NaN            211000000          NaN                  06   \n",
      "198           NaN            211000000          NaN                  06   \n",
      "199           NaN            211000000          NaN                  06   \n",
      "200           NaN            211000000          NaN                  06   \n",
      "201           NaN            211000000          NaN                  06   \n",
      "\n",
      "     RIDE_STA_ID  ... PASGR_NUM1  PASGR_NUM2  PASGR_NUM3  USE_DIST  USE_TIME  \\\n",
      "0            311  ...          1           0           0    9700.0    1518.0   \n",
      "1            153  ...          1           0           0     900.0     197.0   \n",
      "2           2535  ...          1           0           0    9700.0    2435.0   \n",
      "3        9012125  ...          1           0           0    1058.0     524.0   \n",
      "4            311  ...          1           0           0   22400.0    2793.0   \n",
      "..           ...  ...        ...         ...         ...       ...       ...   \n",
      "197          223  ...          1           0           0     900.0     267.0   \n",
      "198          223  ...          1           0           0     900.0     306.0   \n",
      "199          220  ...          1           0           0    3200.0     756.0   \n",
      "200          223  ...          1           0           0    4000.0    1055.0   \n",
      "201          237  ...          1           0           0   10700.0    2323.0   \n",
      "\n",
      "     RIDE_DATE  RIDE_TIME  ALIGHT_DATE  ALIGHT_TIME        TIME_CATEGORY  \n",
      "0   2013-12-15   15:14:34   2013-12-15     15:39:52        Non-Peak (NP)  \n",
      "1   2013-12-15   15:59:40   2013-12-15     16:02:57        Non-Peak (NP)  \n",
      "2   2013-12-15   18:24:58   2013-12-15     19:05:33  Afternoon Peak (AP)  \n",
      "3   2013-12-15   19:46:13   2013-12-15     19:54:57  Afternoon Peak (AP)  \n",
      "4   2013-12-16   07:37:31   2013-12-16     08:24:04    Morning Peak (MP)  \n",
      "..         ...        ...          ...          ...                  ...  \n",
      "197 2013-12-21   13:47:40   2013-12-21     13:52:07        Non-Peak (NP)  \n",
      "198 2013-12-21   11:13:46   2013-12-21     11:18:52        Non-Peak (NP)  \n",
      "199 2013-12-21   15:45:38   2013-12-21     15:58:14        Non-Peak (NP)  \n",
      "200 2013-12-21   16:07:04   2013-12-21     16:24:39  Afternoon Peak (AP)  \n",
      "201 2013-12-21   19:27:17   2013-12-21     20:06:00  Afternoon Peak (AP)  \n",
      "\n",
      "[202 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df['TIME_CATEGORY'] = df['RIDE_TIME'].apply(categorize_time)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"D:\\\\0-transportation project\\\\000E0E0E96E3BFC3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine most frequent station for given conditions\n",
    "def identify_stations(df, user_id_col, station_id_col, time_cat):\n",
    "    filtered = df[df['TIME_CATEGORY'] == time_cat]\n",
    "    return filtered.groupby([user_id_col, station_id_col]).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False).drop_duplicates(subset=[user_id_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying homes and workplaces\n",
    "def find_places(df):\n",
    "    # Most-departed station during morning peak hours for home\n",
    "    homes_morning = identify_stations(df, 'PCARD_NO', 'RIDE_STA_ID', 'Morning Peak (MP)')\n",
    "    # Most-visited station during afternoon peak hours for home\n",
    "    homes_afternoon = identify_stations(df, 'PCARD_NO', 'ALIGHT_STA_ID', 'Afternoon Peak (AP)')\n",
    "\n",
    "    # Most-visited station during morning peak hours for workplace\n",
    "    work_morning = identify_stations(df, 'PCARD_NO', 'ALIGHT_STA_ID', 'Morning Peak (MP)')\n",
    "    # Most-departed station during afternoon peak hours for workplace\n",
    "    work_afternoon = identify_stations(df, 'PCARD_NO', 'RIDE_STA_ID', 'Afternoon Peak (AP)')\n",
    "\n",
    "    # Most-visited stations during non-peak hours for other activities\n",
    "    other_activities = identify_stations(df, 'PCARD_NO', 'ALIGHT_STA_ID', 'Non-Peak (NP)')\n",
    "\n",
    "    # Merging to create a comprehensive dataframe\n",
    "    homes = pd.merge(homes_morning, homes_afternoon, on='PCARD_NO', suffixes=('_morning', '_afternoon'))\n",
    "    workplaces = pd.merge(work_morning, work_afternoon, on='PCARD_NO', suffixes=('_morning', '_afternoon'))\n",
    "\n",
    "    return homes, workplaces, other_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes, workplaces, other_activities = find_places(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Homes Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCARD_NO</th>\n",
       "      <th>RIDE_STA_ID</th>\n",
       "      <th>counts_morning</th>\n",
       "      <th>ALIGHT_STA_ID</th>\n",
       "      <th>counts_afternoon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000E0E0E96E3BFC3</td>\n",
       "      <td>311</td>\n",
       "      <td>6</td>\n",
       "      <td>433.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PCARD_NO  RIDE_STA_ID  counts_morning  ALIGHT_STA_ID  \\\n",
       "0  000E0E0E96E3BFC3          311               6          433.0   \n",
       "\n",
       "   counts_afternoon  \n",
       "0                 9  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample Homes Data:\")\n",
    "homes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Workplaces Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCARD_NO</th>\n",
       "      <th>ALIGHT_STA_ID</th>\n",
       "      <th>counts_morning</th>\n",
       "      <th>RIDE_STA_ID</th>\n",
       "      <th>counts_afternoon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000E0E0E96E3BFC3</td>\n",
       "      <td>331.0</td>\n",
       "      <td>6</td>\n",
       "      <td>331</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PCARD_NO  ALIGHT_STA_ID  counts_morning  RIDE_STA_ID  \\\n",
       "0  000E0E0E96E3BFC3          331.0               6          331   \n",
       "\n",
       "   counts_afternoon  \n",
       "0                 7  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample Workplaces Data:\")\n",
    "workplaces.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Other Activities Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCARD_NO</th>\n",
       "      <th>ALIGHT_STA_ID</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000E0E0E96E3BFC3</td>\n",
       "      <td>331.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PCARD_NO  ALIGHT_STA_ID  counts\n",
       "14  000E0E0E96E3BFC3          331.0      15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample Other Activities Data:\")\n",
    "other_activities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripid(df):\n",
    "    # Ensure RIDE_TIME and ALIGHT_TIME are combined with RIDE_DATE and ALIGHT_DATE if needed\n",
    "    df['RIDE_DATETIME'] = pd.to_datetime(df['RIDE_DTIME'])\n",
    "    df['ALIGHT_DATETIME'] =pd.to_datetime(df['ALIGHT_DTIME'])\n",
    "\n",
    "    # Sort by PCARD_NO and RIDE_DATETIME\n",
    "    df = df.sort_values(['PCARD_NO', 'RIDE_DATETIME'])\n",
    "\n",
    "    # Shift ALIGHT_DATETIME to line up with the next RIDE_DATETIME\n",
    "    df['NEXT_RIDE_TIME'] = df.groupby('PCARD_NO')['RIDE_DATETIME'].shift(-1)\n",
    "\n",
    "    # Calculate time difference in minutes between ALIGHT_DATETIME and the next RIDE_DATETIME\n",
    "    df['TIME_DIFF'] = (df['NEXT_RIDE_TIME'] - df['ALIGHT_DATETIME']).dt.total_seconds() / 60\n",
    "\n",
    "    # Identify trip boundaries where the time difference is more than 30 minutes\n",
    "    df['NEW_TRIP'] = (df['TIME_DIFF'] > 30).astype(int)\n",
    "\n",
    "    # Cumulatively sum the NEW_TRIP flags to create unique trip IDs for each PCARD_NO\n",
    "    df['TRIP_ID'] = df.groupby('PCARD_NO')['NEW_TRIP'].cumsum()\n",
    "\n",
    "    # Now, df contains an additional column 'TRIP_ID' that indicates the unique trip number for each transaction\n",
    "    return df[['PCARD_NO', 'RIDE_DATETIME', 'ALIGHT_DATETIME', 'NEXT_RIDE_TIME', 'TIME_DIFF', 'NEW_TRIP', 'TRIP_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time strings to timedelta\n",
    "df['RIDE_TIMEDELTA'] = pd.to_timedelta(df['RIDE_TIME'])\n",
    "df['ALIGHT_TIMEDELTA'] = pd.to_timedelta(df['ALIGHT_TIME'])\n",
    "df['RIDE_DTIME'] = pd.to_datetime(df['RIDE_DTIME'])\n",
    "# Add the timedelta to the datetime date fields to get full datetime fields\n",
    "df['RIDE_DATETIME'] = df['RIDE_DATE'] + df['RIDE_TIMEDELTA']\n",
    "df['ALIGHT_DATETIME'] = df['ALIGHT_DATE'] + df['ALIGHT_TIMEDELTA']\n",
    "\n",
    "# You can now drop the extra timedelta columns if they are no longer needed\n",
    "df.drop(['RIDE_TIMEDELTA', 'ALIGHT_TIMEDELTA'], axis=1, inplace=True)\n",
    "\n",
    "# Continue with your operations such as sorting and calculating differences\n",
    "df = df.sort_values(['PCARD_NO', 'RIDE_DATETIME'])\n",
    "df['NEXT_RIDE_TIME'] = df.groupby('PCARD_NO')['RIDE_DATETIME'].shift(-1)\n",
    "df['TIME_DIFF'] = (df['NEXT_RIDE_TIME'] - df['ALIGHT_DATETIME']).dt.total_seconds() / 60\n",
    "df['NEW_TRIP'] = (df['TIME_DIFF'] > 30).astype(int)\n",
    "df['TRIP_ID'] = df.groupby('PCARD_NO')['NEW_TRIP'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'DatetimeArray' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_1\u001b[38;5;241m=\u001b[39mdata_date_time(df_11_1)\n\u001b[0;32m      2\u001b[0m df_1\u001b[38;5;241m=\u001b[39mdata_time(df_11_1)\n\u001b[1;32m----> 3\u001b[0m df_1\u001b[38;5;241m=\u001b[39m\u001b[43mtripid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_1)\n",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mtripid\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtripid\u001b[39m(df):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Ensure RIDE_TIME and ALIGHT_TIME are combined with RIDE_DATE and ALIGHT_DATE if needed\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIDE_DATETIME\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRIDE_DATE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIDE_TIME\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALIGHT_DATETIME\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALIGHT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALIGHT_TIME\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Sort by PCARD_NO and RIDE_DATETIME\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:6126\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6125\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 6126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:273\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    267\u001b[0m     should_extension_dispatch(left, right)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'DatetimeArray' and 'str'"
     ]
    }
   ],
   "source": [
    "df_1=data_date_time(df_11_1)\n",
    "df_1=data_time(df_11_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PCARD_NO      RIDE_DTIME  TRANS_ID  TRANSP_METHOD_CD  \\\n",
      "374596  000E0E0E96E3BFC3  20131215151434       175               200   \n",
      "374597  000E0E0E96E3BFC3  20131215155940       176               200   \n",
      "374598  000E0E0E96E3BFC3  20131215182458       177               200   \n",
      "374599  000E0E0E96E3BFC3  20131215194613        21               105   \n",
      "\n",
      "        TRAF_FREQ  BUS_ROUTE_ID  RIDE_TRANSP_BIZR_ID      VEHC_ID  \\\n",
      "374596          0           NaN            211000000          NaN   \n",
      "374597          0           NaN            211000000          NaN   \n",
      "374598          0           NaN            211200000          NaN   \n",
      "374599          0    11110084.0            111520030  111755108.0   \n",
      "\n",
      "        PCARD_USER_CLASS_CD  RIDE_STA_ID  ... FARE_USER_CLASS_CD3  PASGR_NUM1  \\\n",
      "374596                    6          311  ...                 NaN           1   \n",
      "374597                    6          153  ...                 NaN           1   \n",
      "374598                    6         2535  ...                 NaN           1   \n",
      "374599                    6      9012125  ...                 NaN           1   \n",
      "\n",
      "        PASGR_NUM2  PASGR_NUM3  USE_DIST  USE_TIME  ALIGHT_DATE  ALIGHT_TIME  \\\n",
      "374596           0           0    9700.0    1518.0   2013-12-15     15:39:52   \n",
      "374597           0           0     900.0     197.0   2013-12-15     16:02:57   \n",
      "374598           0           0    9700.0    2435.0   2013-12-15     19:05:33   \n",
      "374599           0           0    1058.0     524.0   2013-12-15     19:54:57   \n",
      "\n",
      "        RIDE_DATE  RIDE_TIME  \n",
      "374596 2013-12-15   15:14:34  \n",
      "374597 2013-12-15   15:59:40  \n",
      "374598 2013-12-15   18:24:58  \n",
      "374599 2013-12-15   19:46:13  \n",
      "\n",
      "[4 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_21748\\416533948.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ALIGHT_DATETIME'] =pd.to_datetime(df['ALIGHT_DTIME'])\n"
     ]
    },
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Parsing \"20131215153952.0\" to datetime overflows, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mparsing.pyx:684\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_1\u001b[38;5;241m=\u001b[39m\u001b[43mtripid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_1)\n",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m, in \u001b[0;36mtripid\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtripid\u001b[39m(df):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Ensure RIDE_TIME and ALIGHT_TIME are combined with RIDE_DATE and ALIGHT_DATE if needed\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIDE_DATETIME\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIDE_DTIME\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALIGHT_DATETIME\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mALIGHT_DTIME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Sort by PCARD_NO and RIDE_DATETIME\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCARD_NO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIDE_DATETIME\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:692\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m: Parsing \"20131215153952.0\" to datetime overflows, at position 0"
     ]
    }
   ],
   "source": [
    "df_1=tripid(df_1)\n",
    "print(df_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
